\chapter{Verwandte Arbeiten}
\label{relatedwork}

\begin{itemize}
 \item 1-2 Paper pro Thema sollte reichen
 \item für die Bibliographie: auch Info-Fachbücher zitieren für die Datenstrukturen z.B.
\end{itemize}

An dieser Stelle möche ich einige Veröffentlichungen vorstellen, welche sich mit ähnlichen Problemstellungen befassen, wie die vorliegende Arbeit.
\section{Paralleles Rendering}
Beim parallelen Rendering geht es um die Verteilung von Aufgaben in einer Netzwerktopologie. Dies kann entweder durch einfaches Multithreading oder durch einen Rechnervebund (Cluster) geschehen. Dabei wird meist entweder das Rendern selber in verschiedene Unteraufgaben geteilt. Eine weitere Möglichkeit ist auch die Trennung von Aufgaben, die im Eigentlichen nichts miteinander zu tun haben, wie zum Beispiel Trennung der Daten-Verwaltung von der Bilderzeugung.\\*
In den letzten Jahren wurden viele Möglichkeiten zur Verteilung der Aufgaben in parallelen Rendersystemen veröffentlicht. Molnar et al.\cite{molnar} klassifizieren Parallelisierungsstrategien in drei Kategorien, in Abhängigkeit davon, an welcher Stelle der Rendering-Pipeline Polygone nach ihrer Sichtbarkeit sortiert werden.\linebreak\linebreak
Sort-First-Algorithmen teilen den Bildschirm in disjunkte Regionen ein (Kacheln) und weisen jedem Renderer eine solche Kachel zu. Jeder Render ist für die gesamte Bilderzeugung in diesem einem Bildabschnitt zuständig. Geometrische Objekte werden zu den Renderer übertragen, wenn diese in der jeweiligen Kachel sichtbar sind. Sort-First-Renderer nutzen die Frame-to-Frame Kohärenz gut aus, da nur wenige geometrische Primitive zwischen einzelnen Frames die Bildausschnitte wechseln. Die Rendering-Algorithmen sind bei Sort-First frei wählbar, da jeder Renderer die vollständige Geometrie für seine Kachel besitzen muss. Allerdings kann es sein, dass sich viele geometrische Objekte der gesamten Szene auf wenige Kacheln verteilen, wodurch die Lastverteilung aus dem Gleichgewicht gerät. Ein weiterer Nachteil ist, dass Objekte von mehrern Renderern gezeichnet werden müssen.\linebreak\linebreak
Sort-Middle-Algorithmen teilen den Rendervorgang in Geometrie- und rasteroperationen auf. Geometrische Objekte werden auf verschiedene Geometrieprozessoeren verteilt und Bildteile werden an Rasterizer verteilt. Transformation und Beleuchtung geschieht auf den Geometrieprozessoren, welche ihre Ergebnisse dann an die entsprechenden Rasterizer schicken. Dieses Verfahren eignet sich am Besten für High-End Grafik-Workstations welche aus eng-gekoppelten Systemen bestehen. Für den Versand der Daten zwischen Geometrieprozessoeren und den Rasterizern ist jedoch eine eine hohe Bandbreite vonnöten.\linebreak\linebreak
Sort-Last-Algorithmen verteilen geometrische Objekte an einzelne Renderer. Ein Renderer berechnet Pixelwerte für seine Untermenge an Objekten und verteilt die Farb- und Tiefenwerte an Prozesse, die diese dann vereinigen. Bei großen Objektmengen bietet sich dieses Verfahren an, da jedes geometrische Objekt genau einmal gerendert wird. Für den Pixeltransfer wird allerdings eine hohe Bandbreite vom Netzwerk abverlangt. Da die genaue Tiefe eines Pixels erst bei der Vereinigung der Pixel ermittelt werden kann, ist Sort-Last für einige Rendertechniken, wie Transparenz oder Antialiasing, ungeeignet.\linebreak\linebreak
Samanta et al.\cite{samanta} haben einen hybriden Renderer entwickelt, welcher Sort-First und Sort-Last Ansätze kombiniert. Geometrische Objekte werden gruppiert nach der minimalen Überlappung ihrer Boundingboxen und anschließend auf Sort-Last Rechenknoten verteilt. Besitzen mehrere Knoten überlappende Objekte, werden die berechneten Tiefenwerde ausgetauscht und mit ihren eigenen Ergänzt. So erhält jeder Renderer ein nahezu korrektes Tiefenabbild. Die fertigen Farbpixel werden am Ende an einen speziellen Kachelrenderer weitergeleitet, welcher lediglich die Kacheln zsuammen setzt und darstellt. Der gesamte Pixelversand wird mittels peer-to-peer im Netzwerk verteilt, wodurch eine verbesserte Netzlastnutzung mit verringerten Latenzen möglich ist.\linebreak
2002 stellten Baxter et al.\cite{baxter} ein paralleles Walkthrough-System ``Gigawalk'' vor. Das System fasst Objekte zu sogenannten Clustern zusammen. In einem Minimalen Spannbaum wird die minimale Ausdehnung eines Clusters berechnet um mehrere Cluster miteinander verbinden zu können. Eine hierarische Gruppierung ergibt sich über die Boundingboxen der einzelnen Cluster, woraus ein Szene-Graph erzeugt wird. Aus dieser Hierarchie werden verschiedene Levels-of-Detail (LOD)\cite{hlod} generiert, um bei komplexen Objekten flexibel bleiben zu können. All dies geschieht im Preprozessing. Druch Frustumculling werden zur Laufzeit Potentially Visible Sets zusammen gestellt, also Mengen an wahrscheinlich sichtbaren Clustern. Um zu verhindern, dass verdeckte Objekte gezeichnet werden wird ein hierrischer Z-Buffer verwendet, welche ein Occlusionculling durchführt. Als hierarchische Occluder kommen dabei die berechneten LODs zum Einsatz. Die gesamte Kommunikation erfolgt durch Shared-Memory-Queues. Dieses System wurde mit SGI Onyx Workstations getestet und kommt bei 80 Millionen Dreiecken auf 11-50 Bilder pro Sekunde.\linebreak
Ein anderer Ansatz wird von \cite{dpbp} verfolgt um mit Multicluster-Systemen zu arbeiten, also Institutsübergreifend zu rendern. Dabei kommt ein Sort-First-Algorithmus zum Einsatz mit dem auch gekachelte Bildsysteme angesteuert werden können, wie die CAVE \cite{cave} oder die Powerwall am Heinz-Nixdorf Institut. Im Preprocessing wird die räumliche Verteilung von Objekten zu Clustern zusammengefasst. Um eine hierarchische Gewichtung zu erhalten werden die projizierten Cluster-Boundingboxen in sogenannten Pixel-Buckets sortiert und gerendert.\linebreak
Ähnlich arbeitet man bei \cite{DBLP:journals/ijvr/YinJSZ06}. Da dort Terrain-Daten berechnet werden kommt dieses System ohne Frustum-Culling aus, da solche Daten keine große Tiefenkomplexität besitzen. Bemerkenswert bei dieser Arbeit ist jedoch, dass die Datenstruktur, ein Quadtree, im Preprozessing erzeugt wird und binar auf Festplatte gespeichert wird. Somit wird ein ständiges Erzeugen einer geeigneten räumlichen Aufteilung des Modells hinfällig. Der Fokus der Arbeit liegt allerdings in der Kalibrierung des Beamerystems, welches unter Verwendung von Aplha-Blending sichtbare Kanten zwischen einzelnen Displays entfernt.

Um der potenziellen ungleich verteilten Last bei Sort-First-Ansätzen entgegen zu wirken, haben Abraham et al. \cite{abraham} einen parallelen Renderer entwickelt der die Kachelgrößen automatisch anhand der letzten Renderzeit der jeweiligen Kachel anpasst. Jedem Renderknoten im Netzwerk liegt dabei das 3D-Modell vollständig vor. Ein Thread ist immer für die Bilderzeugung zuständig, während ein Weiterer sich um den Versand und Empfang von Nachrichten im Netzwerk kümmert. Der Renderknoten, der in einem Frame als erster seine Bildkachel abliefert, bekommt im nächsten Frame die Kachel mit dem höchsten Aufand zugeteilt. Dieses Kacheltauschen ist jedoch für Out-of-Core Systeme ungeeignet, da die Objektdaten dann ebenfalls umverteilt werden müssen. Außerdem ist ein homogener Rechencluster notwendig, damit Unterschiede in den Rechenzeiten nicht bedingt durch unterschiedliche Hardware sind. Das Testsystem besteht aus 10 Pentum 4-PCs mit je 512MB RAM, einer GeForce 4 Grafikkarte und einer GigaBit Ethernet Anbindung.\linebreak

\section{Out-of-core Rendering}
Von Out-of-Core Rendering wird gesprochen, wenn ein zu renderndes 3D-Modell nicht vollständig in den Arbeitsspeicher der Grafikkarte passt. Man könnte Teile des Modells entfernen bis der verbleibende Rest nicht mehr zu groß für den Speicher ist. Teilweise wird dies auch gemacht, führt jedoch zu Bildfehlern, da Teile fehlen können, die eigentlich sichtbar sind. Eine weitere Möglichkeit besteht darin, kleinere Mengen des Modells einzeln zu rendern und am Ende die Bilder zu vereinigen. Das resultierende Bild ist so zwar fehlerfrei, allerdings geht dieses Verfahren zulasten der Rendergeschwindigkeit. Interaktive Bildraten können so wahrscheinlich nicht erzielt werden.\linebreak
Manocha et al. \cite{manocha} stellen ein Out-of-Core System vor mit dem sich interaktive Bildraten in einm Verbund mehrer SGI Workstations erzielen lassen. Multi-Threading 
\textit{Out of core rendering in massive geometric environments}
\begin{itemize}
 \item Out-of-Core, Scene-Grapth, diverses Culling
 \item verwendet Prefetching mit LOD-Switching
 \item statische LODs werden vorberechnet
 \item 2 Prozesse: einer render und cullt und der andere kümmert sich um Prefetching und Disk I/O
 \item Nimmt Darstellungsfehler in Kauf, durch noch nicht geladene, jedoch angeforderte Objekte
 \item Vergrößertes Frustum fürs PreCaching. Größ ändert sich dynamisch mit Bewegungsgeschwindigkeit.
 \item Zusätzlich werden Objeke, die nur im erweiterten Frustum liegen durch ihren Blickwinkel priorisiert. D.h. Objekte die näher am Zentrum der Kamera liegen werden bevorzugt.
 \item Ein weiteres Maß für Priorität liefert die Klassifizierung von Objekten durch deren Screen-Space Error
 \item SGI Workstation, 195Mhz, MXI graphics board, 128MB Ram und einer SGI Onyx mit mehreren 500Mhz Prozessoren und Infinite Reality 3 graphics pipelines und 16GB Ram
\end{itemize}

\cite{wagner1}: \textit{out-of-core sort-first parallel rendering for cluster-based tiled displays}
\begin{itemize}
 \item Sort-first, out-of-core und parallel
 \item Cluster von 16 PCs mit je 512MB RAM
 \item ist eine parallele Erweiterung von iWalk
 \item System ist speziell für High-Res Bilder(4096x3072) gedacht
 \item Hierarchische Representation des Modells auf Platte
 \item \textbf{Paper enthält sehr dateilierte Beschreibung der Sorts von Molnar[4.2]}
 \item Algorithmus benutzt ein Verfahren zur bestimmung sichbarer Geometrie unter Einhalötung eines Kontingents (Dreiecke oder Speichergröße) [PLP]
 \item Wie so viele Systeme verlässt sich auch dieses auf gegebene Bildähnlichkeiten zwischen 2 Frames
\end{itemize}

\cite{wagner2}: \textit{Visibility-based pre-fetching for interactive out-of-core rendering.}
\begin{itemize}
 \item Out-of-core
 \item 13 Million Dreiecke interaktiv
 \item Basiert auf iWalk
 \item räumliche Unterteilung auf Platte
 \item geocache läuft als separater Thread. Von der aktuellen Kamerposition wird festgestellt, welche Geometrie demnächst benötigt werden könnte. Sollte der Geocache mit Ladevorgängen den aktuellen Frame betreffend beschäftigt sein, werden Prefetching-Requests ignoriert.
 \item benutzt prioritized-layered projection (PLP) um Menge der sichtbaren Octree-Knoten zu bestimmen.
 \item Weiterer Vorteil von PLP entsteht durch Erzeugung der hirarchischen Struktur zur Preprozessing-Zeit. Damit ist eine Bestimmung des visual sets ohne Zugriff auf tatsächliche Szenen-Geometrie möglich.
 \item LRU wird als Verdrängungsstrategie genutzt
 \item Durchschnittlich 10fps auf einem Pentium4
\end{itemize}

\cite{wald}: \textit{An Interactive Out-of-Core Rendering Framework for Visualizing Massively Complex Models.}
\begin{itemize}
 \item Out-of-core
 \item benutzt auch raytracing
 \item Verwendet Geometrie-Proxies um das ganze Modell auf einem PC zu rendern.
 \item Hat auch die Boeing 777 gerendert
 \item Dual-Core 1.8GHz Operton mit 6GB RAM
 \item Neues Speichermamangement via memory-mapped I/O (mmap())
 \item Preprozessing erzeugt binäre Daten aus dem Modell um schreibt diese auf Platt für mmap.
 \item System übernimmt die Verwaltung welche Speicherseiten in Hauptspeicher liegen. DUrch Systemaufrufe kann dem Kernel gesagt werden, ob er Seiten auslagern soll oder eher länger im Haupstpeicher belassen soll.
 \item Dieses recht aufwenidige Verfahren ist notwendig da Raytracing benutzt wird, was bei häufigen PageFaults an Interaktivität einbüßt.
 \item Decaching: zyklisch geht ein Thread alle Speicherkacheln durch und setzt das uesed-bit auf null. Sollte die Kachel doch in naher Zukunft benötigt werden, wird das Bit vom Renderer resetet. Findet Thread allerdings eine Kachel bei der use-bit bereits auf 0 gesetzt ist, wird die Kachel aus dem Speicher entfernt.
 \item Geometrie-Proxies werden vom Raytracer apriori gesampelt. SOllte ein Raytracer an Stelle kommen wo eine Speicherseite nicht verfügbar ist, wird die Speicheradresse des benötigten Teils als Schlüssel für eine stl-map verwendet um so an den entsprechenden Proxie zu gelangen.
 \item bei 640x480 3-7 fps
\end{itemize}

\cite{gao}: \textit{Efficient view-dependent out-of-core rendering of large scale and complex scenes.}
\begin{itemize}
 \item out-of-core
 \item Partitionierung der Szene in Hierarchie und Hierarchical level-of-detail (HLOD)
 \item Multi-Threaded: render-thread und prefretching-thread
 \item rendering: Hierarchie für grobe Geometrie-AUflösung und HLOD für feine Auflösung im Lokalen.
 \item Preprozessing: Rekursive räumliche Aufteilung des Modells aufgrund von Objektgrößen (Ausdehnung) und begrenzter Dreiecksanzahl.
 \item Das Preprozessing arbeitet Out-of-core, da immer nur ein Objekt angefasst wird
 \item Rendering auch out-of-core
 \item LRU als Cache-Verdrängungsstrategie
 \item avg framerate 13fps
 \item FrustumCulling aber kein OcclusionCulling
\end{itemize}

\section{Randomized Sample Tree}
Jeweils kurze Einleitung was das ist\\*
sampletree: \cite{klein}: \textit{The randomized sample tree: a data structure for interactive walkthroughs in externally stored virtual environments}\\*

\section{c-Collision Protokoll}
Jeweils kurze Einleitung was das ist\\*
c-Collision?: \cite{DBLP:conf/arcs/RehbergS99}: \textit{Almost optimal schedules with a simple protocol}
\begin{itemize}
 \item -
\end{itemize}


