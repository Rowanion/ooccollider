\chapter{Evaluierung}
\label{chap:eval}
\todo[size=\small, inline]{2 exemplarische Kammerapositionen noch einfügen hier sowie den Walkthrough-Pfad.....aber wo?}%
\todo[size=\small, inline]{Compiler Version, libversions, treiberversionen graka, boostlib opengl Auflösung und Auflösung des Ext. Frustums hinschreiben}%
\todo[size=\small, inline]{Diagramme Nebeneinander!}%
Um die Effektivität des in dieser Arbeit entstandenen Systems überprüfen zu können, wurden verschiedene Tests durchgeführt.
Beim ersten Test, dem \textit{FPS-Test}, wurde die gemessene Bildrate bei einem Walkthrough\footnote{\todo[size=\small,inline]{Walkthrough-Erklärung an erste Stelle des Auftauchens innerhalb der Arbeit schieben. Vermutlich Intro.}Ein Walkthrough bezeichnet hier eine Navigation durch eine 3D-Szene bei der möglichst viele signifikante Stellen des Modells besucht werden.} durch die Szene aufgezeichnet. Der \textit{Reload-Test} hat bei verschiedenen Systemkonfigurationen an festen Kamerapositionen die Zeit gemessen, die ein erneutes Laden der Szene benötigt. Beim \textit{$c$-Collision-Test} wurde die Last der einzelnen Datenknoten während eines Walkthroughs gemessen. Die einzelnen Testläufe unterscheiden sich dabei in der verwendeten Anzahl an Datenknoten und Redundanzen. Redundanz bedeutet hier, wie oft das Modell der Boeing vollständig im Netzwerk verteilt wurde. \\
Zur Entwicklung des Systems wurde ein kleinerer Cluster benutzt, bestehend aus 8 Pentium Multicore-Rechnern in einem GigaBit Netzwerk, sowie einem Quadcore-Pentium mit einer GeForce 260GTX Grafikkarte als Render- und Masterknoten, im Folgenden \textit{Entwicklungs-Cluster} genannt. Durch  Speicher limit nur Redundanz 1. Die eigentlichen Tests erfolgten auf dem Arminius-Cluster des PC$^2$s (siehe Tabelle \ref{tab:impl:arminius}), im Folgenden als \textit{Test-Cluster} bezeichnet.\\
Im \textit{Test-Cluster} wurde der Compiler gcc 3.4.6, OpenGL als Grafik-API, nVidia Treiber v190 auf den Rechenknoten und v\textbf{???} auf den Visualisierungsknoten benutzt, sowie die boost-Bibliothek v1.38 und OpenMPI v1.2.9. Die Auflösung betrug jeweils 640$\times$480 Pixel für das normale Frustum und 800$\times$600 Pixel für das erweiterte Frustum.\\
Zusätzliche Diagramme und Abbildungen sind in den Anhängen \ref{chap:add_diag} und \ref{chap:add_fig} zu finden.

\section{FPS-Test}
\label{sec:eval:fps}

Bei diesem Test wurde in einem festgelegten Walkthrough durch die 3D-Szene gemessen, wieviele Bilder pro Sekunde an welcher Stelle der Szene erreicht werden konnten. Dazu wurde der Walkthrough auf je 24, 28 und 32 Datenknoten mit einer Redundanz von 1, 2 und 3 durchgeführt. Die y-Achsen der Diagramme \ref{fig:eval:fps1} und \ref{fig:eval:fps3} stellen die Bilder pro Sekunde dar und die x-Achsen die Position innerhalb des Walkthroughs.

\begin{figure}
\centering
\input{plots/diag_fps_redundancy1.tex}
  \caption{\label{fig:eval:fps1}FPS in einem Walkthrough. (Redundanz$=$1, 2 Renderer und 24-32 Datenknoten)}
\end{figure}
An den Diagrammen kann man sehen, dass sich die Bildrate bei verschiedenen Konfigurationen ähnelt. Allerdings lassen sich keine Zusammenhänge zwischen Bildrate und Redundanz oder Knotenanzahl herstellen. Die Bildrate gibt eher Rückschlüsse darauf, wie die Szene an den einzelnen Positionen beschaffen ist. An Stellen des Modells, wo sehr viel Geometrie angefordert werden muss, ist die Bildrate vermutlich geringer, als an Stellen, an denen weniger Angefordert wird. Hinzu kommt der Umstand, dass die Grafikkarten der Datenknoten im hier verwendeten \textit{Test-Cluster}, nicht sehr Leistungsstark sind. In Testumgebungen mit aktuellerer Grafikhardware würde die Zahl der Redundanzen und der Knoten möglicherweise stärker ins Gewicht fallen. Trotz geringerer Netzwerk-Bandbreite, konnten im \textit{Entwicklungs-Cluster} teilweise höhere FPS gemessen werden, als im \textit{Test-Cluster}. Beim gleichen Walkthrough auf dem \textit{Entwicklungs-Cluster} zeigte sich, dass nach kurzer Zeit kaum noch Objekte dargestellt wurden. Durch die kontinuierliche Bewegung wird der Tiefenbuffer alle 20 Frames aktualisiert, was zur Folge hat, dass alle laufenden Aufträge verworfen werden. In dem langsameren Netzwerk kamen dadurch kaum noch Objekte bei den Renderknoten an. Die Geschwindigkeit des verwendeten Netzwerks hat somit Auswirkungen auf die Bildqualität.
\begin{figure}
\centering
\input{plots/diag_fps_redundancy3.tex}
  \caption{\label{fig:eval:fps3}FPS in einem Walkthrough. (Redundanz$=$3, 2 Renderer und 24-32 Datenknoten)}
\end{figure}

\section{Reload-Test}
\label{sec:eval:reload}

Beim Reload-Test wurde an festgelegten Kamerapositionen gemessen, wie lange die einzelnen Datenknoten benötigen, um die für diese Szene anfallenden Aufträge, vollständig zu bearbeiten. Dazu wurden sämtliche auf den Renderern befindliche Objekte verworfen und erneut angefordert. War ein Datenknoten mit der Bearbeitung aller Aufträge fertig, hat er sich beim Masterknoten zurückgemeldet und die gemessene Zeit wurde gespeichert.\\
\begin{figure}
\centering
\input{plots/test10.tex}
  \caption{\label{fig:eval:reload1}Reloadtest: Redundanz 1, 2 Renderknoten, 24 Datenknoten.}
\end{figure}
Die Diagramme \ref{fig:eval:reload1} und \ref{fig:eval:reload6} enthalten auf den x-Achsen die Kameraposition und auf den y-Achsen die Render-Zeit in Sekunden. In den Diagrammen ist zu erkennen, dass der Median meist nahe am Durchschnitt liegt. Die Messungen wurden dabei mehrfach durchgeführt und die Ergebnisse wurden gemittelt. Ab und zu sind zwar einige Ausreißer zu erkennen, aber selbst die 0.25 und 0.75 Quantile liegen meist sehr dicht am Median. Das bedeutet, dass das System gut balanciert. Nur wenige Knoten benötigen mehr Zeit zum Rendern ihrer Aufträge als das beim Median der Fall ist. Jedoch lässt auch dieser Test keinen Zusammenhang zwischen Redundanzen, Knotenanzahl und der benötigten Zeit erkennen. Die Beschaffenheit der Szene an einer gegebenen Kameraposition scheint ausschlaggebend für die gesamte benötigte Bearbeitungszeit zu sein. Mehr Geometrie an einer Position bedeutet auch mehr zu vergebene Aufträge, was mehr Zeit in Anspruch nimmt, als das bei weniger Geometrie der Fall ist.

\begin{figure}
%\begin{Bild}
\centering
\input{plots/test15.tex}
  \caption{\label{fig:eval:reload6}Reloadtest: Redundanz 3, 2 Renderknoten, 32 Datenknoten.}
%\end{Bild}
\end{figure}
\begin{comment}
\begin{Bild}
\input{plots/Reload7_r1_24.tex}
  \captionof{figure}{Reloadtest: R1, 24 Datenknoten.}
\end{Bild}
\begin{Bild}
\input{plots/Reload7_r1_28.tex}
  \captionof{figure}{Reloadtest: R1, 28 Datenknoten.}
\end{Bild}
\begin{Bild}
\input{plots/Reload7_r1_32.tex}
  \captionof{figure}{Reloadtest: R1, 32 Datenknoten.}
\end{Bild}

\begin{Bild}
\input{plots/Reload7_r3_24.tex}
  \captionof{figure}{Reloadtest: R3, 24 Datenknoten.}
\end{Bild}
\begin{Bild}
\input{plots/Reload7_r3_28.tex}
  \captionof{figure}{Reloadtest: R3, 28 Datenknoten.}
\end{Bild}
\begin{Bild}
\input{plots/Reload7_r3_32.tex}
  \captionof{figure}{Reloadtest: R3, 32 Datenknoten.}
\end{Bild}

\begin{Bild}
\input{plots/test5.tex}
  \captionof{figure}{Reloadtest: Redundanz 2, 2 Renderknoten, 32 Datenknoten.}
\end{Bild}

\begin{Bild}
\input{plots/test9.tex}
  \captionof{figure}{Reloadtest: Redundanz 2, 2 Renderknoten, 24 Datenknoten.}
\end{Bild}
\end{comment}

\section{\textit{c}-Collision-Test}
\label{sec:eval:ccollision}

Der Test für das $c$-Collision Protkoll wurde als Einziger nicht im Cluster durchgeführt, sondern ausschließlich in einer Simulation. Dafür wurden alle Anfragen bei einem tatsächlichen Walkthrough durch die Szene aufgezeichnet, unmittelbar bevor sie durch das $c$-Collision Protkoll vergeben wurden. Anschließend wurden diese Aufzeichnungen genutzt, um eine beliebige Datenknotenmenge zu simulieren. Im \textit{Test-Cluster} standen für diese Arbeit maximal 2 Visualisierungsknoten und 32 Datenknoten zur Verfügung, weshalb die Menge der Datenknoten in dieser Simulation erhöht wurde. Andere Mengen an Renderknoten lassen sicht nicht ohne Weiteres simulieren, da die Renderknoten bestimmen, wann welche Objekte benötigt werden. Deshalb sind keine realistischen Mutmaßungen über Anfragefolgen bei künstlich veränderter Renderknotenmenge möglich.\\
In diesem Test wurden 24, 80 und 120 Datenknoten simuliert. Dabei wurde die Last in Form von Dreiecken gemessen, die in jedem Frame an jeden Datenknoten vergeben wurde. In diesem Test wurden verschiedene Zufalls-Seeds benutzt und das Ergebnis wurde gemittelt.\\
Das linke Diagramm zeigt jeweils die Walkthrough-Position (x-Achse) in Relation zur Lastverteilung (y-Achse). Das rechte Diagramm zeigt jeweils die Anfragenmenge, die durch das $c$-Collision Protkoll pro Frame verteilt wurde (x-Achse) in Relation zur Lastverteilung (y-Achse). Bei Betrachtung des linken Diagramms fallen einige Positionen auf, an denen die Last sehr ungleich verteilt ist oder der Median 0 ist. Im rechten Diagramm kann man sehen, dass dies immer dann der Fall ist, wenn sehr wenige Anfragen an das $c$-Collision Protkoll übergeben wurden. Dieses Protokoll dient ursprünglich dazu, Bälle möglichst gleichmäßig auf Körbe zu verteilen. Hat man viel weniger Bälle als Körbe, ist das System nicht gleichmäßig balanciert, da einige Körbe gar keine Bälle erhalten. Sowie die Bälle sind auch die Anfragen im Test-System atomar und werden nicht weiter unterteilt. Je nach initialer Zufallsverteilung der Daten auf den Knoten, kann es bei wenig Redundanzen auch vorkommen, dass die Aufträge nur auf wenige Knoten verteilt werden können. Im Falle des benutzen Walkthroughs, treten die unbalancierten Stelle da auf, wo das Model betreten und verlassen wird. An diesen Stellen gibt es sehr wenig sichtbare Geometrie.\\
Bei diesem Test ist zu erkennen, dass sowohl die Menge an Knoten als auch die Zahl der Redundanzen eine Rolle bei der gleichmäßigen Lastverteilung spielt. Bei erhöhter Redundanz ist zu beobachen, dass die 0.1 und 0.9 Quantile sehr viel Näher am Median liegen als bei geringerer Redundanz. Mehr Datenknoten sorgen dafür, dass die Spitzenwerte an unbalancierten Stellen geringer ausfallen.
\begin{comment}
\begin{itemize}
\item $c$-Collision: Mehr Redundanz = Mittlere Auslastung wird reduziert (blaue durchscnittsdistanz zum median)
\item $c$-Collision: Last ist gut verteilt, wenn Anzahl an Requests hinreichend groß ist
\item $c$-Collision: Bei wenigen Anfragen sehr unbalanciert = wenige Knoten haben überhaupt was zu tun
\item $c$-Collision: Wenige Anfragen = wenig zu sehen (3. drittel, gang aus dem Flugzeug raus = keine Objekte)
\item $c$-Collision: Mehr Knoten = mehr Ausgeglichenheit bei Imbalance-Peaks $\rightarrow$ kann aber sein, dass das einfach durch die Knotenmenge runterskaliert wird. Die Anfragenzahl ist ja gleich.
\end{itemize}
\end{comment}
\begin{Bild}
\includegraphics[scale=0.75]{images/diag_cCol_red1_render4_data24_2x.pdf}
  \captionof{figure}{\label{fig:eval:cCol1}Die Auslastung der Datenknoten in einem Walkthrough bei 4 Renderknoten und 24 Datenknoten und Redundanz$=$1.}
\end{Bild}

\begin{Bild}
\includegraphics[scale=0.75]{images/diag_cCol_red3_render4_data120_2x.pdf}
  \captionof{figure}{\label{fig:eval:cCol9}Die Auslastung der Datenknoten in einem Walkthrough bei 4 Renderknoten und 120 Datenknoten und Redundanz$=$3.}
\end{Bild}
